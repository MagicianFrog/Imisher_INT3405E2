{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# --- CẤU HÌNH TỐI ƯU CHO T4 x2 ---\n",
    "CFG = {\n",
    "    'model_name': 'facebook/esm2_t33_650M_UR50D',\n",
    "    'input_dim': 1280,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    \n",
    "    # Cấu hình Extraction\n",
    "    'extract_batch_size': 16,\n",
    "    'max_len': 1024,\n",
    "    \n",
    "    'data_path': '/kaggle/input/cafa-6-protein-function-prediction'\n",
    "}\n",
    "\n",
    "print(f\">>> ĐANG CHẠY TRÊN: {CFG['device']}\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"Chỉ tìm thấy 1 GPU\")\n",
    "\n",
    "# ====================================================\n",
    "# PHẦN 1: TRÍCH XUẤT EMBEDDINGS (ESM-2 650M)\n",
    "# ====================================================\n",
    "print(\"\\n[1/5] CHECKING EMBEDDINGS...\")\n",
    "\n",
    "TRAIN_EMB_FILE = 'X_train_650M.npy'\n",
    "TEST_EMB_FILE = 'X_test_650M.npy'\n",
    "\n",
    "def extract_embeddings_heavy(sequences, save_path):\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\" -> File {save_path} đã tồn tại. Bỏ qua bước này.\")\n",
    "        return\n",
    "\n",
    "    print(f\" -> Đang khởi tạo model {CFG['model_name']}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG['model_name'])\n",
    "    model = AutoModel.from_pretrained(CFG['model_name'])\n",
    "    \n",
    "    # KÍCH HOẠT 2 GPU\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    model.to(CFG['device'])\n",
    "    model.eval()\n",
    "    \n",
    "    embeddings = []\n",
    "    print(f\" -> Bắt đầu xử lý {len(sequences)} sequences...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(sequences), CFG['extract_batch_size']), desc=\"Extracting\"):\n",
    "            batch_seqs = sequences[i : i + CFG['extract_batch_size']]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_seqs, \n",
    "                return_tensors=\"pt\", \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                max_length=CFG['max_len']\n",
    "            )\n",
    "            inputs = {k: v.to(CFG['device']) for k, v in inputs.items()}\n",
    "            \n",
    "            # Forward pass (Mixed Precision để tăng tốc & giảm VRAM)\n",
    "            if torch.cuda.is_available():\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(**inputs)\n",
    "            else:\n",
    "                outputs = model(**inputs)\n",
    "            \n",
    "            # Lấy Mean Pooling (Bỏ qua padding)\n",
    "            last_hidden_state = outputs.last_hidden_state\n",
    "            attention_mask = inputs['attention_mask'].unsqueeze(-1)\n",
    "            \n",
    "            # Tính mean thủ công để chính xác\n",
    "            masked_hidden = last_hidden_state * attention_mask\n",
    "            sum_hidden = masked_hidden.sum(dim=1)\n",
    "            sum_mask = attention_mask.sum(dim=1)\n",
    "            batch_emb = sum_hidden / sum_mask\n",
    "            \n",
    "            # Lưu dạng float16\n",
    "            embeddings.append(batch_emb.cpu().numpy().astype(np.float16))\n",
    "\n",
    "    # Gộp và Lưu\n",
    "    full_emb = np.vstack(embeddings)\n",
    "    np.save(save_path, full_emb)\n",
    "    print(f\" -> Đã lưu {save_path}: {full_emb.shape}\")\n",
    "    \n",
    "    # Dọn dẹp GPU\n",
    "    del model, tokenizer, embeddings, full_emb\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# --- HÀM ĐỌC DATA ---\n",
    "def get_seqs(path):\n",
    "    seqs = []\n",
    "    ids = [] \n",
    "    with open(path, 'r') as f:\n",
    "        current_seq = []\n",
    "        prev_header = \"\"\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                if current_seq: \n",
    "                    seqs.append(\"\".join(current_seq))\n",
    "                    # Lấy ID chuẩn\n",
    "                    ids.append(prev_header.strip()[1:].split('|')[1] if '|' in prev_header else prev_header.strip()[1:].split()[0])\n",
    "                current_seq = []\n",
    "                prev_header = line\n",
    "            else:\n",
    "                current_seq.append(line.strip())\n",
    "        if current_seq: \n",
    "            seqs.append(\"\".join(current_seq))\n",
    "            ids.append(prev_header.strip()[1:].split('|')[1] if '|' in prev_header else prev_header.strip()[1:].split()[0])\n",
    "    return ids, seqs\n",
    "\n",
    "# --- THỰC THI EXTRACT ---\n",
    "print(\" -> Reading FASTA files...\")\n",
    "# Đọc file Train và Test từ đường dẫn Kaggle\n",
    "train_ids, train_seqs = get_seqs(f\"{CFG['data_path']}/Train/train_sequences.fasta\")\n",
    "test_ids, test_seqs = get_seqs(f\"{CFG['data_path']}/Test/testsuperset.fasta\")\n",
    "\n",
    "# Chạy Extract\n",
    "extract_embeddings_heavy(train_seqs, TRAIN_EMB_FILE)\n",
    "extract_embeddings_heavy(test_seqs, TEST_EMB_FILE)\n",
    "\n",
    "print(\"\\n>>> HOÀN THÀNH EXTRACT EMBEDDINGS!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14875579,
     "sourceId": 116062,
     "sourceType": "competition"
    },
    {
     "datasetId": 8909009,
     "sourceId": 14171385,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 285361219,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
