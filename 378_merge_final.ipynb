{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# tại cell code này thì sẽ tạo ra submission chưa qua post-processing, điểm đạt được là 0.375\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# --- CẤU HÌNH TRỌNG SỐ VÀ LỌC ---\n",
    "W_SUBMISSION363 = 0.99\n",
    "W_SUBMISSION261 = 0.01 \n",
    "MIN_SCORE_THRESHOLD = 0.01 \n",
    "\n",
    "print(f\"-> Tỷ lệ: SUBMISSION363({W_SUBMISSION363}) + SUBMISSION261({W_SUBMISSION261})\")\n",
    "\n",
    "# 1. TÌM FILE\n",
    "def find_file(filename):\n",
    "    files = glob.glob(f'/kaggle/input/**/{filename}', recursive=True)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"Lỗi: Không tìm thấy file '{filename}'\")\n",
    "    return files[0]\n",
    "\n",
    "try:\n",
    "    path_submission363 = find_file('ksub3.tsv')\n",
    "    path_submission261 = find_file('lsub.tsv')\n",
    "    \n",
    "    print(f\"Found SUBMISSION363: {path_submission363}\")\n",
    "    print(f\"Found SUBMISSION261: {path_submission261}\")\n",
    "except Exception as e:\n",
    "    print(f\"LỖI: {e}\")\n",
    "    raise\n",
    "\n",
    "# 2. ĐỌC DỮ LIỆU\n",
    "dtypes = {'id': 'string', 'term': 'string'} \n",
    "\n",
    "df_submission363 = pd.read_csv(\n",
    "    path_submission363,\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=['id', 'term', 'score_submission363'],\n",
    "    dtype=dtypes\n",
    ")\n",
    "\n",
    "df_submission261 = pd.read_csv(\n",
    "    path_submission261,\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=['id', 'term', 'score_submission261'],\n",
    "    dtype=dtypes\n",
    ")\n",
    "\n",
    "# 3. TRỘN (MERGE)\n",
    "print(\"-> Merging...\")\n",
    "df_blend = pd.merge(\n",
    "    df_submission363,\n",
    "    df_submission261,\n",
    "    on=['id', 'term'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# 4. TÍNH ĐIỂM (DYNAMIC WEIGHTED AVERAGE)\n",
    "print(\"-> Calculating Weighted Average...\")\n",
    "\n",
    "# ÉP KIỂU BẮT BUỘC\n",
    "df_blend['score_submission363'] = pd.to_numeric(\n",
    "    df_blend['score_submission363'], errors='coerce'\n",
    ")\n",
    "df_blend['score_submission261'] = pd.to_numeric(\n",
    "    df_blend['score_submission261'], errors='coerce'\n",
    ")\n",
    "\n",
    "# Điền 0 vào chỗ thiếu\n",
    "score_submission363_temp = df_blend['score_submission363'].fillna(0)\n",
    "score_submission261_temp = df_blend['score_submission261'].fillna(0)\n",
    "\n",
    "# TỬ SỐ\n",
    "numerator = (\n",
    "    score_submission363_temp * W_SUBMISSION363\n",
    "    + score_submission261_temp * W_SUBMISSION261\n",
    ")\n",
    "\n",
    "# MẪU SỐ\n",
    "weight_submission363_active = (\n",
    "    df_blend['score_submission363'].notna().astype(float) * W_SUBMISSION363\n",
    ")\n",
    "weight_submission261_active = (\n",
    "    df_blend['score_submission261'].notna().astype(float) * W_SUBMISSION261\n",
    ")\n",
    "denominator = weight_submission363_active + weight_submission261_active\n",
    "\n",
    "# Xử lý chia cho 0 / NaN\n",
    "df_blend['score'] = numerator / denominator\n",
    "df_blend['score'] = df_blend['score'].fillna(0)\n",
    "\n",
    "# 5. LỌC VÀ LƯU FILE\n",
    "print(\"-> Filtering and Saving...\")\n",
    "\n",
    "# 5a. Lọc ngưỡng tối thiểu\n",
    "df_final = df_blend[df_blend['score'] >= MIN_SCORE_THRESHOLD].copy()\n",
    "\n",
    "# 5b. Loại bỏ trùng lặp\n",
    "df_final.drop_duplicates(subset=['id', 'term'], keep='first', inplace=True)\n",
    "\n",
    "# 5c. Sắp xếp theo ID\n",
    "df_final = df_final.sort_values('id', ascending=True)\n",
    "\n",
    "# 5d. Chọn cột, format và lưu\n",
    "df_final = df_final[['id', 'term', 'score']]\n",
    "df_final['score'] = df_final['score'].map('{:.3f}'.format)\n",
    "df_final.to_csv('submission.tsv', sep='\\t', header=False, index=False)\n",
    "\n",
    "print(f\"DONE! {len(df_final)} dòng.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nâng điểm lên 0.378\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CẤU HÌNH ĐƯỜNG DẪN ---\n",
    "INPUT_SUBMISSION = '/kaggle/input/merge-notebook/submission.tsv' #file cần xử lý\n",
    "OBO_FILE = '/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo'\n",
    "OUTPUT_FILE = 'submission.tsv'\n",
    "\n",
    "# --- PHẦN 1: HÀM ĐỌC CẤU TRÚC OBO ---\n",
    "def parse_go_obo(obo_path):\n",
    "    print(f\"Loading OBO from: {obo_path} ...\")\n",
    "    go_parents = defaultdict(set)\n",
    "    current_id = None\n",
    "    \n",
    "    # Mở file và đọc từng dòng\n",
    "    with open(obo_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"id: GO:\"):\n",
    "                current_id = line.split(\"id: \")[1]\n",
    "            elif line.startswith(\"is_a: GO:\") and current_id:\n",
    "                parent = line.split(\"is_a: \")[1].split(\" !\")[0]\n",
    "                go_parents[current_id].add(parent)\n",
    "            elif line.startswith(\"relationship: part_of GO:\") and current_id:\n",
    "                parent = line.split(\"relationship: part_of \")[1].split(\" !\")[0]\n",
    "                go_parents[current_id].add(parent)\n",
    "                \n",
    "    print(f\"-> Đã load xong quan hệ cha-con của {len(go_parents)} GO terms.\")\n",
    "    return go_parents\n",
    "\n",
    "# --- PHẦN 2: HÀM TÌM TỔ TIÊN (ĐỆ QUY CÓ CACHE) ---\n",
    "def get_ancestors(go_term, go_parents, cache):\n",
    "    # Nếu đã tính rồi thì trả về ngay (Memoization)\n",
    "    if go_term in cache:\n",
    "        return cache[go_term]\n",
    "    \n",
    "    parents = set()\n",
    "    # Lấy cha trực tiếp\n",
    "    direct_parents = go_parents.get(go_term, [])\n",
    "    \n",
    "    for p in direct_parents:\n",
    "        parents.add(p)\n",
    "        parents.update(get_ancestors(p, go_parents, cache))\n",
    "        \n",
    "    cache[go_term] = parents\n",
    "    return parents\n",
    "\n",
    "# --- PHẦN 3: LOGIC LAN TRUYỀN (PROPAGATION) ---\n",
    "def propagate_scores(df, go_parents):\n",
    "    print(\"Bắt đầu lan truyền điểm số (Propagation)...\")\n",
    "    \n",
    "    # Chuyển DataFrame thành Dictionary để xử lý cho nhanh\n",
    "    # Cấu trúc: data[protein_id] = {go_term: score, ...}\n",
    "    data = defaultdict(dict)\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Reading CSV\"):\n",
    "        data[row[0]][row[1]] = float(row[2]) # row[0]=ID, row[1]=Term, row[2]=Score\n",
    "    \n",
    "    final_rows = []\n",
    "    ancestor_cache = {} # Cache để không phải tìm lại tổ tiên nhiều lần\n",
    "    \n",
    "    # Duyệt qua từng Protein\n",
    "    for protein_id, terms_dict in tqdm(data.items(), desc=\"Propagating\"):\n",
    "        # Copy ra dict mới để chứa điểm sau khi lan truyền\n",
    "        propagated_dict = terms_dict.copy()\n",
    "        \n",
    "        # Duyệt qua từng term hiện có của protein đó\n",
    "        for go_term, original_score in terms_dict.items():\n",
    "            # Lấy tất cả tổ tiên của term này\n",
    "            ancestors = get_ancestors(go_term, go_parents, ancestor_cache)\n",
    "            \n",
    "            # Cập nhật điểm cho tổ tiên\n",
    "            for ancestor in ancestors:\n",
    "                current_score = propagated_dict.get(ancestor, 0.0)\n",
    "                # Logic Max: Điểm tổ tiên = Max(Điểm cũ của nó, Điểm của con cháu)\n",
    "                if original_score > current_score:\n",
    "                    propagated_dict[ancestor] = original_score\n",
    "        \n",
    "        # Lưu lại kết quả vào list\n",
    "        for term, score in propagated_dict.items():\n",
    "            if score >= 0.001: # Lọc nhẹ bớt các điểm quá thấp để giảm dung lượng\n",
    "                final_rows.append((protein_id, term, score))\n",
    "                \n",
    "    return final_rows\n",
    "\n",
    "# --- MAIN ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Đọc dữ liệu\n",
    "    if not os.path.exists(OBO_FILE):\n",
    "        print(\"Lỗi\")\n",
    "        exit()\n",
    "        \n",
    "    go_parents = parse_go_obo(OBO_FILE)\n",
    "    \n",
    "    print(f\"Reading submission: {INPUT_SUBMISSION}\")\n",
    "    df = pd.read_csv(INPUT_SUBMISSION, sep='\\t', header=None, names=['Id', 'Term', 'Score'])\n",
    "    \n",
    "    # 2. Xử lý\n",
    "    result_data = propagate_scores(df, go_parents)\n",
    "    \n",
    "    # 3. Xuất file\n",
    "    print(f\"Saving to {OUTPUT_FILE}...\")\n",
    "    result_df = pd.DataFrame(result_data, columns=['Id', 'Term', 'Score'])\n",
    "    \n",
    "    # Format float 3\n",
    "    result_df.to_csv(OUTPUT_FILE, sep='\\t', header=False, index=False, float_format='%.3f')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14875579,
     "sourceId": 116062,
     "sourceType": "competition"
    },
    {
     "datasetId": 8909009,
     "sourceId": 14171385,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 285361219,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
